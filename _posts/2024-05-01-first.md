---
layout: post
title: "Starting My Blog in the Age of AI"
date: 2024-11-17
reading_time: 5 minutes
description: Why human-written blogs still matter in the AI era
tags: [blogging, ai, thoughts]
categories: [reflections]
toc: true
---

Hello! This is my first blog post in a long time. Since finishing my PhD, I've had lots of ideas I wanted to write about but never got around to it. When AI tools like ChatGPT came along, I wondered if blogging was still worth it. After thinking about it, I'm sure it is - we just need to blog differently now.

Here's why I think blogging is still useful (and why I'm doing it):

## Sharing What We Know
AI tools can give us loads of information - sometimes too much! But blog posts can do something different. They can show you a clear path to learn something new. 

For example, I follow some operational researchers on LinkedIn. Their posts have shown me interesting ideas I'd never have thought to ask AI about. That's what I want to do here - leave little trails of knowledge that you can follow. While AI is good at telling you more about things you already know, blogs can help you discover completely new things!

## Sharing What We Experience
The other day, I read a great post on Hacker News by [arguingwithalgorithms](https://www.arguingwithalgorithms.com/posts/cursor-review.html) about using a tool called Cursor. I would never have known about this if they hadn't shared their experience. While AI needs our experiences to learn from, we need each other's stories to learn what works in real life. No need to say more.

## Sharing What We Discover
LLMs don't discover new things. They don't test the comparison between different MILP solvers (yet). But we can. And we should. Moreover, they don't have our structured data! This might have been considered an advantage of LLMs, working with unstructured data, but I think they should have access to structured data (let's say our CSV and Excel files) to discover new things. Once I wanted to generate a huge and hard knapsack instance to solve. It was successful in generating huge instances, but not smart enough to make them hard and not random. This means LLMs won't be able to discover new insights about actual real challenges (until someone does this manually and posts it in a blog).

Let me know what you think!